{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow has many abstraction!\n",
    "- TF Learn\n",
    "- Keras\n",
    "- TF-Slim\n",
    "- Layers\n",
    "- Estimator API\n",
    "- and more!\n",
    "\n",
    "*and many of them are reside in tf.contrib section*\n",
    "\n",
    "Lets apply using wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine_data = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_data = wine_data['data']\n",
    "labels = wine_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(feat_data,labels,\n",
    "                                                 test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_train = scaler.fit_transform(x_train)\n",
    "scaled_x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESTIMATOR API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [tf.feature_column.numeric_column('x', shape=[13])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\CODEHA~1\\AppData\\Local\\Temp\\tmp_bdy_5tr\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\CODEHA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp_bdy_5tr', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001DB3575DF28>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "deep_model = estimator.DNNClassifier(hidden_units=[13,13,13],\n",
    "                                    feature_columns = feat_cols,\n",
    "                                    n_classes=3, #according to ds\n",
    "                                    optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = estimator.inputs.numpy_input_fn(x={'x':scaled_x_train},\n",
    "                                          y=y_train,\n",
    "                                          shuffle=True,\n",
    "                                          batch_size=10,\n",
    "                                          num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\codehax41\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\codehax41\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\codehax41\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\codehax41\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\codehax41\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\CODEHA~1\\AppData\\Local\\Temp\\tmp_bdy_5tr\\model.ckpt.\n",
      "INFO:tensorflow:loss = 11.138456, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 62 into C:\\Users\\CODEHA~1\\AppData\\Local\\Temp\\tmp_bdy_5tr\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.1457624.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x1db3575dc18>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.train(input_fn=input_fn,steps =500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn_eval = estimator.inputs.numpy_input_fn(x={'x':scaled_x_test},\n",
    "                                               shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Users\\codehax41\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\CODEHA~1\\AppData\\Local\\Temp\\tmp_bdy_5tr\\model.ckpt-62\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "preds = list(deep_model.predict(input_fn=input_fn_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [p['class_ids'][0] for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93        19\n",
      "           1       1.00      0.77      0.87        22\n",
      "           2       0.87      1.00      0.93        13\n",
      "\n",
      "   micro avg       0.91      0.91      0.91        54\n",
      "   macro avg       0.91      0.92      0.91        54\n",
      "weighted avg       0.92      0.91      0.90        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KERAS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_keras_model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_keras_model.add(layers.Dense(units=13, input_dim=13, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_keras_model.add(layers.Dense(units=13, activation='relu'))\n",
    "dnn_keras_model.add(layers.Dense(units=13, activation='relu'))\n",
    "dnn_keras_model.add(layers.Dense(units=3, activation='softmax')) #o/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import losses,optimizers,metrics,activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_keras_model.compile(optimizer='adam',\n",
    "                       loss='sparse_categorical_crossentropy',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 6ms/sample - loss: 1.0391 - acc: 0.4194\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 0s 117us/sample - loss: 1.0286 - acc: 0.4113\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 0s 137us/sample - loss: 1.0183 - acc: 0.4113\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 0s 129us/sample - loss: 1.0088 - acc: 0.4113\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 0s 133us/sample - loss: 0.9985 - acc: 0.4113\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 0s 157us/sample - loss: 0.9873 - acc: 0.4274\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 0s 177us/sample - loss: 0.9763 - acc: 0.4516\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 0s 173us/sample - loss: 0.9643 - acc: 0.4516\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 0s 189us/sample - loss: 0.9521 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 0s 121us/sample - loss: 0.9394 - acc: 0.5887\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 0s 121us/sample - loss: 0.9264 - acc: 0.5968\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 0s 157us/sample - loss: 0.9118 - acc: 0.6371\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 0s 181us/sample - loss: 0.8965 - acc: 0.6774\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 0s 411us/sample - loss: 0.8807 - acc: 0.7097\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 0s 113us/sample - loss: 0.8643 - acc: 0.7258\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 0s 133us/sample - loss: 0.8459 - acc: 0.7419\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 0s 229us/sample - loss: 0.8270 - acc: 0.7581\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 0s 121us/sample - loss: 0.8072 - acc: 0.7823\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 0s 125us/sample - loss: 0.7876 - acc: 0.7984\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 0s 185us/sample - loss: 0.7671 - acc: 0.7984\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 0s 105us/sample - loss: 0.7466 - acc: 0.8226\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 0s 205us/sample - loss: 0.7250 - acc: 0.8548\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 0s 117us/sample - loss: 0.7042 - acc: 0.8548\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 0s 129us/sample - loss: 0.6814 - acc: 0.8548\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 0s 109us/sample - loss: 0.6586 - acc: 0.8629\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 0s 145us/sample - loss: 0.6349 - acc: 0.8629\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.6298 - acc: 0.875 - 0s 173us/sample - loss: 0.6107 - acc: 0.9032\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 0s 125us/sample - loss: 0.5871 - acc: 0.9194\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 0s 165us/sample - loss: 0.5623 - acc: 0.9194\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 0s 169us/sample - loss: 0.5394 - acc: 0.9194\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 0s 121us/sample - loss: 0.5153 - acc: 0.9194\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 0s 189us/sample - loss: 0.4922 - acc: 0.9274\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 0s 169us/sample - loss: 0.4688 - acc: 0.9274\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 0s 145us/sample - loss: 0.4460 - acc: 0.9355\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 0s 201us/sample - loss: 0.4220 - acc: 0.9435\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 0s 173us/sample - loss: 0.4001 - acc: 0.9435\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 0s 113us/sample - loss: 0.3788 - acc: 0.9677\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 0s 161us/sample - loss: 0.3580 - acc: 0.9677\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 0s 157us/sample - loss: 0.3384 - acc: 0.9677\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 0s 169us/sample - loss: 0.3200 - acc: 0.9677\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 0s 109us/sample - loss: 0.3023 - acc: 0.9677\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 0s 185us/sample - loss: 0.2857 - acc: 0.9677\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 0s 149us/sample - loss: 0.2693 - acc: 0.9677\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 0s 129us/sample - loss: 0.2545 - acc: 0.9677\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 0s 161us/sample - loss: 0.2403 - acc: 0.9677\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 0s 161us/sample - loss: 0.2269 - acc: 0.9677\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 0s 113us/sample - loss: 0.2154 - acc: 0.9677\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 0s 149us/sample - loss: 0.2033 - acc: 0.9758\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 0s 137us/sample - loss: 0.1937 - acc: 0.9758\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 0s 137us/sample - loss: 0.1829 - acc: 0.9758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1db395a84a8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_keras_model.fit(scaled_x_train,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dnn_keras_model.predict_classes(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        17\n",
      "           1       0.95      0.91      0.93        23\n",
      "           2       1.00      0.93      0.96        14\n",
      "\n",
      "   micro avg       0.94      0.94      0.94        54\n",
      "   macro avg       0.95      0.95      0.95        54\n",
      "weighted avg       0.95      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAYERS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codehax41\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "one_hot_y_train=pd.get_dummies(y_train).as_matrix() #layers api only take data as matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codehax41\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "one_hot_y_test=pd.get_dummies(y_test).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat = 13\n",
    "num_hidden1 = 13\n",
    "num_hidden2=13\n",
    "num_outputs = 3\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,shape=[None,num_feat])\n",
    "y_true = tf.placeholder(tf.float32,shape=[None,3])\n",
    "actf = tf.nn.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = fully_connected(x,num_hidden1, activation_fn=actf)\n",
    "hidden2 = fully_connected(hidden1,num_hidden2, activation_fn=actf)\n",
    "output = fully_connected(hidden2,num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=y_true,logits=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = optimizer.minimize(loss)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_step = 50\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(training_step):\n",
    "        sess.run(train,feed_dict={x:scaled_x_train,y_true:one_hot_y_train})\n",
    "    logits = output.eval(feed_dict={x:scaled_x_test})\n",
    "    preds = tf.argmax(logits,axis=1) #highest prob.\n",
    "    results = preds.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        16\n",
      "           1       1.00      0.88      0.94        25\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "   micro avg       0.94      0.94      0.94        54\n",
      "   macro avg       0.95      0.96      0.95        54\n",
      "weighted avg       0.95      0.94      0.95        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(results,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
